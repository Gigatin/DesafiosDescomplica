{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97246ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imagina que o projeto de analise textual que por exemplo categoriza a artigos que são submetidos a um site ou noticias que sejam digitalizadas e automaticamente categorizadas\n",
    "#então esse processo vai ser automatizado para que uma pessoa não tenha que fazer isso\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "920846b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/csv/news/bbc-text.csv')\n",
    "df.head()\n",
    "#aqui já tem as repostas da categoria mas o foco do projeto é não precisar usar dele\n",
    "#também é necessario transformar o texto em informações numericas para a anlise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b76fc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "sport            511\n",
       "business         510\n",
       "politics         417\n",
       "tech             401\n",
       "entertainment    386\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checando as categorias\n",
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a239f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([511, 510, 417, 401, 386], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#listando quantas noticias há de cada um\n",
    "total_categorias = df.category.value_counts().values\n",
    "total_categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bd2890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from time import time\n",
    "\n",
    "#vetorizando as palavras\n",
    "# max_df =  palavras ou termos que aparecem em mais de 50% dos documentos\n",
    "#min df =  que aparecem em ao menos 5 documentos\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.5,\n",
    "    min_df=5,\n",
    "    stop_words=\"english\", #removendo stopwords por não ter valor de informações\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aebec39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vetorização completa em 0.378 s\n",
      "n_observacoes: 2225, n_features: 9136\n"
     ]
    }
   ],
   "source": [
    "#aplicando o vetorizador no conjunto de dados\n",
    "t0 = time()\n",
    "X_tfidf = vectorizer.fit_transform(df.text)\n",
    "print(f\"vetorização completa em {time() - t0:.3f} s\")\n",
    "print(f\"n_observacoes: {X_tfidf.shape[0]}, n_features: {X_tfidf.shape[1]}\")\n",
    "#2225 observações e + de 9000 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26f0128f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014\n"
     ]
    }
   ],
   "source": [
    "#quantas variaveis de fatos foram encontradas?\n",
    "#Apenas 14% tem valor diferente de 0\n",
    "print(f\"{X_tfidf.nnz / np.prod(X_tfidf.shape):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4907c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de elementos em cada cluster: [298 317 508 821 281]\n",
      "Número de elementos em cada cluster: [510 779 489 142 305]\n",
      "Número de elementos em cada cluster: [264 912 490 386 173]\n",
      "Número de elementos em cada cluster: [758 525 404 169 369]\n",
      "Número de elementos em cada cluster: [780 540 390 171 344]\n",
      "\n",
      "Número de documentos em cada cluster real: [511 510 417 401 386]\n"
     ]
    }
   ],
   "source": [
    "#diminuindo os valores de 0\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "for seed in range(5):\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=5,\n",
    "        max_iter=100,\n",
    "        n_init=1,\n",
    "        random_state=seed,\n",
    "    ).fit(X_tfidf)\n",
    "    cluster_ids, cluster_sizes = np.unique(kmeans.labels_, return_counts=True)\n",
    "    print(f\"Número de elementos em cada cluster: {cluster_sizes}\")\n",
    "print()\n",
    "print(\n",
    "    \"Número de documentos em cada cluster real: \"\n",
    "    f\"{total_categorias}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de0edef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA concluido em 0.316 s\n",
      "Variação explicado do SVD: 26.3%\n"
     ]
    }
   ],
   "source": [
    "#redução de dimensionalidade LSA\n",
    "from sklearn.decomposition import TruncatedSVD #para diminuir o tempo e aumentar a qualidade de analise\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "\n",
    "lsa = make_pipeline(TruncatedSVD(n_components=100), Normalizer(copy=False)) # Criando um pipeline com TruncatedSVD e Normalizer\n",
    "t0 = time() # Gravando o tempo antes de iniciar a transformação\n",
    "X_lsa = lsa.fit_transform(X_tfidf) # Aplicando o pipeline para transformar o conjunto de dados X_tfidf\n",
    "explained_variance = lsa[0].explained_variance_ratio_.sum() # Calculando a variância explicada pelos componentes principais retidos\n",
    "\n",
    "print(f\"LSA concluido em {time() - t0:.3f} s\") # Imprimindo o tempo de execução do LSA\n",
    "print(f\"Variação explicado do SVD: {explained_variance * 100:.1f}%\") # Imprimindo a variância explicada pelo SVD truncado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a638214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=2 - silhueta=0.041\n",
      "k=2 - rand_index=0.331\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "k=3 - silhueta=0.050\n",
      "k=3 - rand_index=0.570\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "k=4 - silhueta=0.059\n",
      "k=4 - rand_index=0.644\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "k=5 - silhueta=0.070\n",
      "k=5 - rand_index=0.909\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "k=6 - silhueta=0.072\n",
      "k=6 - rand_index=0.867\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "k=7 - silhueta=0.075\n",
      "k=7 - rand_index=0.764\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "k=8 - silhueta=0.075\n",
      "k=8 - rand_index=0.699\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "k=9 - silhueta=0.079\n",
      "k=9 - rand_index=0.584\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n"
     ]
    }
   ],
   "source": [
    "#rodando algoritmo\n",
    "#encontrando silhueta\n",
    "#rand_index = metrica \n",
    "#é observado que com k = 5 o index é mais alto o que faz sentido por haver só 5 grupos\n",
    "for i in range(2,10):\n",
    "    kmeans_model = KMeans(n_clusters=i, random_state=42).fit(X_lsa)\n",
    "    labels = kmeans_model.labels_\n",
    "    print(f\"k={i} - silhueta={metrics.silhouette_score(X_lsa, labels, metric='euclidean'):.3f}\")\n",
    "    print(f\"k={i} - rand_index={metrics.adjusted_rand_score(df.category.values, labels):.3f}\")\n",
    "    print(20*' * ')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81e912ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checando quais palavras impactam mais os grupos\n",
    "kmeans = KMeans(\n",
    "    n_clusters=5,\n",
    "    max_iter=100,\n",
    "    n_init=1,\n",
    "    random_state=seed,\n",
    ").fit(X_lsa)\n",
    "\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed3030f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: game england cup club win play players match chelsea injury \n",
      "Cluster 1: company growth market shares bank firm economy sales mr oil \n",
      "Cluster 2: mr labour election government blair party minister people brown howard \n",
      "Cluster 3: film people tv mobile new technology best software digital users \n",
      "Cluster 4: music band album best world record olympic singer rock race \n"
     ]
    }
   ],
   "source": [
    "# gerando clusters de palavras mais frequentes\n",
    "original_space_centroids = lsa[0].inverse_transform(kmeans.cluster_centers_)\n",
    "order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Cluster {i}: \", end=\"\")\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(f\"{terms[ind]} \", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ecbc69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tech', 'business', 'sport', 'entertainment', 'politics'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checando os grupos que estão disponiveis\n",
    "\n",
    "#por exemplo o cluster 4 está ligado a esporte\n",
    "#cluster 1 a business\n",
    "#Cluster 3 Business\n",
    "#cluster 2 a politica\n",
    "df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4472c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
